{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "255c55d0-6510-4289-9d75-f7caaa235879",
   "metadata": {},
   "source": [
    "# Selección y Asignación de pesos: Activos (con ElasticNet + Markowitz)\n",
    "\n",
    "## 1. Universo y filtros iniciales\n",
    "Partimos de un universo amplio $U$ de $\\sim100$ activos ($|U|=100$), compuesto por ETFs core (broad market, sectoriales, commodities, bonos) y acciones *large/mega cap*.  \n",
    "Aplicamos filtros mínimos:\n",
    "\n",
    "1. **Liquidez**:  \n",
    "   $$\n",
    "   \\text{ADV}_i = \\operatorname{median}_{t \\in [t-60,t]} \\big( P_{i,t}\\cdot Vol_{i,t} \\big) \\geq \\theta\n",
    "   $$  \n",
    "   con $\\theta = 5{,}000{,}000\\ \\text{USD}$.\n",
    "2. **Datos completos**: al menos $252$ observaciones diarias sin faltantes.\n",
    "3. **Precio**: descartamos activos con precio efectivo demasiado bajo o con gaps de iliquidez.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Feature engineering\n",
    "Para cada activo $i$ construimos un vector de características cuantitativas:\n",
    "\n",
    "- **Momentos acumulados**:  \n",
    "  $$\n",
    "  r_{i,h} = \\sum_{t=T-h+1}^{T} \\ln\\left(1+R_{i,t}\\right), \\quad h \\in \\{60,126,252\\}\n",
    "  $$\n",
    "- **Volatilidad**:  \n",
    "  $$\n",
    "  \\sigma_{i,h} = \\sqrt{\\frac{1}{h}\\sum_{t=T-h+1}^{T}(R_{i,t}-\\bar R_{i})^2}\n",
    "  $$\n",
    "- **Downside volatility** (solo retornos negativos).  \n",
    "- **Máx. drawdown**:  \n",
    "  $$\n",
    "  \\text{MDD}_i = \\min_{t \\in [0,T]} \\left( \\frac{W_{i,t}}{\\max_{s \\leq t} W_{i,s}} - 1 \\right), \\quad W_{i,t}=(1+R_{i})^{(t)}\n",
    "  $$\n",
    "- **Sensibilidad al mercado** (beta) y correlación con SPY:\n",
    "  $$\n",
    "  \\beta_i = \\frac{\\operatorname{Cov}(R_i, R_{SPY})}{\\operatorname{Var}(R_{SPY})}, \n",
    "  \\quad \\rho_i = \\operatorname{Corr}(R_i, R_{SPY})\n",
    "  $$\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Sharpe ratio como objetivo\n",
    "El ratio de Sharpe individual se calcula como:\n",
    "$$\n",
    "S_i = \\frac{\\mu_i - r_f}{\\sigma_i}\n",
    "$$\n",
    "donde $\\mu_i = E[R_i] \\cdot 252$, $\\sigma_i = \\operatorname{Std}(R_i)\\cdot\\sqrt{252}$ y $r_f$ es la tasa libre de riesgo anualizada.  \n",
    "\n",
    "Esto cuantifica el exceso de retorno ajustado por riesgo de cada activo.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. ElasticNet\n",
    "Se entrena un modelo penalizado:\n",
    "$$\n",
    "\\hat y_i = \\mathbf{x}_i^\\top \\beta,\\quad\n",
    "\\beta = \\arg\\min_{\\beta} \\Bigg\\{ \\frac{1}{n}\\sum_{i=1}^n (y_i - \\mathbf{x}_i^\\top \\beta)^2 \n",
    "+ \\lambda \\Big[ \\alpha \\|\\beta\\|_1 + (1-\\alpha)\\|\\beta\\|_2^2 \\Big] \\Bigg\\}\n",
    "$$\n",
    "- $y_i = S_i$ (Sharpe ratio del activo $i$).  \n",
    "- $\\mathbf{x}_i$ = vector de *features* (momentum, vol, MDD, liquidez, beta, correlación).  \n",
    "- $\\lambda$ controla la magnitud de la penalización, $\\alpha \\in [0,1]$ combina **Lasso** ($\\ell_1$) y **Ridge** ($\\ell_2$).\n",
    "\n",
    "La regresión penalizada identifica qué factores explican mejor el Sharpe ratio y evita sobreajuste y multicolinealidad.\n",
    "\n",
    "Los coeficientes $\\beta_j$ obtenidos se interpretan como **importancia relativa**:  \n",
    "- $\\beta_j > 0$ = característica favorece un Sharpe alto.  \n",
    "- $\\beta_j < 0$ = característica reduce Sharpe esperado.\n",
    "\n",
    "Esto genera un **score ex-ante**:\n",
    "$$\n",
    "\\text{Score}_i = \\sum_{j} Z_{i,j} \\cdot \\hat\\beta_j\n",
    "$$\n",
    "donde $Z_{i,j}$ son las *features* estandarizadas.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Diversificación por clúster\n",
    "Se construye una matriz de correlaciones $\\rho_{ij}$ y una distancia:\n",
    "$$\n",
    "d_{ij} = \\sqrt{2(1-\\rho_{ij})}\n",
    "$$\n",
    "Luego se aplica **KMeans** o clustering jerárquico sobre $d_{ij}$ para agrupar activos en clústeres de alta similitud.  \n",
    "La selección final respeta la restricción:\n",
    "$$\n",
    "|C_k \\cap P| \\leq \\text{cap\\_cluster}\n",
    "$$\n",
    "con $P$ el portafolio elegido. Esto evita redundancia y asegura diversificación.\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Optimización de Markowitz (long-only)\n",
    "Con los activos seleccionados, se optimiza bajo el marco clásico:\n",
    "\n",
    "- **Varianza mínima**:  \n",
    "  $$\n",
    "  \\min_w \\quad w^\\top \\Sigma w\n",
    "  \\quad s.a.\\quad \\mathbf{1}^\\top w = 1,\\; w \\geq 0\n",
    "  $$\n",
    "\n",
    "- **Punto de tangencia (máx. Sharpe)**:  \n",
    "  $$\n",
    "  \\max_w \\quad \\frac{w^\\top \\mu - r_f}{\\sqrt{w^\\top \\Sigma w}}\n",
    "  \\quad s.a.\\quad \\mathbf{1}^\\top w = 1,\\; w \\geq 0\n",
    "  $$\n",
    "\n",
    "donde $\\mu$ es el vector de retornos esperados y $\\Sigma$ la covarianza de Ledoit–Wolf (estimador shrinkage robusto).\n",
    "\n",
    "Se calcula la **frontera eficiente** variando el retorno objetivo $\\tau$:\n",
    "$$\n",
    "\\min_w \\quad w^\\top \\Sigma w\n",
    "\\quad s.a.\\quad \\mathbf{1}^\\top w = 1,\\; \\mu^\\top w = \\tau,\\; w \\geq 0\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## 7. Justificación estratégica\n",
    "- **Sectorial**: exposición diversificada (equity US, internacional, tecnología, energía, defensivos, dividendos).  \n",
    "- **Liquidez**: todos los activos seleccionados tienen ADV elevado.  \n",
    "- **Riesgo-retorno**: ElasticNet prioriza momentum + liquidez y penaliza drawdown/volatilidad → portafolio robusto.  \n",
    "- **Diversificación**: restricción de clúster evita concentrar en un único sector.  \n",
    "- **Optimización eficiente**: pesos finales resultan de Markowitz con restricciones long-only y límites superiores, lo que garantiza factibilidad operativa.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fb0dc9d-adc5-44dd-bc9d-33248e9beae5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26ee3ffa78a84924925c591b30beabd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(VBox(children=(HTML(value='<h3>Selección (Sharpe→ElasticNet + Diversificación por clúster)</h3>…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\proye\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from sklearn.covariance import LedoitWolf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from scipy.optimize import minimize\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import (\n",
    "    Text, FloatText, IntSlider, Button, VBox, HBox, Output, HTML, Dropdown, BoundedFloatText, Checkbox\n",
    ")\n",
    "from IPython.display import display\n",
    "\n",
    "UNIVERSE = [\n",
    "\n",
    "    \"SPY\",\"VOO\",\"QQQ\",\"VTI\",\"IWM\",\"DIA\",\"VTV\",\"VOE\",\"VUG\",\"XLK\",\"SOXX\",\"SMH\",\n",
    "    \"XLF\",\"XLE\",\"XLV\",\"XLY\",\"XLP\",\"XLU\",\"XLB\",\"XLI\",\"XLC\",\n",
    "    \"EFA\",\"EEM\",\"EWJ\",\"EWZ\",\"EWY\",\"EWW\",\"INDA\",\"ASHR\",\n",
    "    \"TLT\",\"IEF\",\"LQD\",\"HYG\",\"GOVT\",\"SHY\",\n",
    "    \"GLD\",\"SLV\",\"USO\",\"UNG\",\"DBA\",\"DBC\",\n",
    "    \"SCHD\",\"VYM\",\"DVY\",\"JEPI\",\"JEPQ\",\n",
    "    \"AAPL\",\"MSFT\",\"GOOGL\",\"META\",\"AMZN\",\"NVDA\",\"AVGO\",\"TSLA\",\n",
    "    \"JNJ\",\"PG\",\"KO\",\"PEP\",\"MCD\",\"WMT\",\"MA\",\"V\",\"HD\",\"LOW\",\n",
    "    \"JPM\",\"BAC\",\"GS\",\"MS\",\"BRK-B\",\"UNH\",\"PFE\",\"ABBV\",\"XOM\",\"CVX\",\"COP\",\n",
    "    \"NKE\",\"COST\",\"ADBE\",\"ORCL\",\"CRM\",\"INTC\",\"AMD\",\"AMAT\",\"ASML\",\"TXN\",\n",
    "    \"CAT\",\"DE\",\"GE\",\"HON\",\"BA\",\"UPS\",\"FDX\",\"RTX\",\"LMT\",\"PLD\",\n",
    "    \"CSCO\",\"QCOM\",\"MU\",\"PANW\",\"CRWD\",\"NOW\",\"SNOW\",\n",
    "    \"MRK\",\"TMO\",\"ABT\",\"MDT\",\"LLY\",\"REGN\",\n",
    "    \"BKNG\",\"ABNB\",\"MAR\",\"CCL\",\"RCL\",\"NFLX\",\"DIS\",\n",
    "]\n",
    "START_DEFAULT = \"2024-01-01\"\n",
    "END_DEFAULT   = \"2025-09-01\"\n",
    "RF_ANNUAL_DEFAULT = 0.00\n",
    "MIN_ADV_USD_DEFAULT = 5_000_000\n",
    "MAX_N_DEFAULT = 7\n",
    "MIN_N_DEFAULT = 4\n",
    "N_CLUSTERS_DEFAULT = 8\n",
    "CAP_PER_CLUSTER_DEFAULT = 2\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "start_sel   = Text(value=START_DEFAULT, description=\"Start:\")\n",
    "end_sel     = Text(value=END_DEFAULT, description=\"End:\")\n",
    "rf_sel      = FloatText(value=RF_ANNUAL_DEFAULT, description=\"RF anual:\")\n",
    "min_adv_sel = FloatText(value=MIN_ADV_USD_DEFAULT, description=\"MIN ADV$:\")\n",
    "max_n_sel   = IntSlider(value=MAX_N_DEFAULT, min=3, max=10, step=1, description=\"Max N:\")\n",
    "min_n_sel   = IntSlider(value=MIN_N_DEFAULT, min=2, max=7, step=1, description=\"Min N:\")\n",
    "k_sel       = IntSlider(value=N_CLUSTERS_DEFAULT, min=3, max=15, step=1, description=\"Clusters:\")\n",
    "cap_sel     = IntSlider(value=CAP_PER_CLUSTER_DEFAULT, min=1, max=4, step=1, description=\"Cap/cluster:\")\n",
    "reselect_btn= Button(description=\"Reseleccionar (ElasticNet)\", button_style=\"primary\")\n",
    "out_head    = HTML(\"<b>Seleccionados:</b> —\")\n",
    "out_coef    = Output()\n",
    "out_select  = Output()\n",
    "\n",
    "tickers_txt = Text(value=\"\", description=\"Tickers:\", layout=dict(width=\"720px\"))\n",
    "start_mkv   = Text(value=START_DEFAULT, description=\"Start:\")\n",
    "end_mkv     = Text(value=END_DEFAULT, description=\"End:\")\n",
    "rf_mkv      = FloatText(value=RF_ANNUAL_DEFAULT, description=\"RF anual:\")\n",
    "grid_slider = IntSlider(value=40, min=10, max=200, step=5, description=\"# puntos:\")\n",
    "obj_dd      = Dropdown(options=[\"Frontera (grid)\", \"Mín-Var\", \"Tangency\"], value=\"Frontera (grid)\", description=\"Objetivo:\")\n",
    "ubound      = BoundedFloatText(value=1.0, min=0.05, max=1.0, step=0.05, description=\"Límite w_i:\")\n",
    "auto_compute= Checkbox(value=True, description=\"Auto-calcular al reseleccionar\")\n",
    "compute_btn = Button(description=\"Calcular frontera\", button_style=\"primary\")\n",
    "sel_idx_slider = IntSlider(value=0, min=0, max=0, step=1, description=\"Punto:\")\n",
    "out_plot   = Output()\n",
    "out_weights= Output()\n",
    "out_info   = Output()\n",
    "\n",
    "def ann_to_daily(x, periods=252):\n",
    "    return (1 + x)**(1/periods) - 1\n",
    "\n",
    "def max_drawdown_from_returns(r):\n",
    "    eq = (1+r).cumprod()\n",
    "    peak = eq.cummax()\n",
    "    dd = eq/peak - 1.0\n",
    "    return float(dd.min())\n",
    "\n",
    "def winsorize(s, p=0.05):\n",
    "    lo, hi = s.quantile(p), s.quantile(1-p)\n",
    "    return s.clip(lo, hi)\n",
    "\n",
    "def download_panel(tickers, start, end):\n",
    "    df = yf.download(tickers, start=start, end=end, auto_adjust=True, progress=False)\n",
    "    if df.empty: \n",
    "        raise RuntimeError(\"Sin datos descargados.\")\n",
    "    px = df[\"Close\"].dropna(how=\"all\", axis=1)\n",
    "    vol = df[\"Volume\"].reindex(px.index).fillna(0).dropna(how=\"all\", axis=1)\n",
    "    cols = sorted(list(set(px.columns) & set(vol.columns)))\n",
    "    px = px[cols].dropna()\n",
    "    vol = vol[cols].loc[px.index]\n",
    "    return px, vol\n",
    "\n",
    "def min_variance_weights(cov, ub=1.0):\n",
    "    n = cov.shape[0]; w0 = np.ones(n)/n\n",
    "    cons = ({\"type\":\"eq\",\"fun\": lambda w: np.sum(w)-1.0},)\n",
    "    bnds = tuple((0.0, float(ub)) for _ in range(n))\n",
    "    obj = lambda w: float(w @ cov @ w)\n",
    "    res = minimize(obj, w0, method=\"SLSQP\", bounds=bnds, constraints=cons, options={\"maxiter\":600})\n",
    "    if not (res.success and np.all(np.isfinite(res.x))):\n",
    "        w = w0\n",
    "    else:\n",
    "        w = res.x\n",
    "    w = np.maximum(w, 0); s = w.sum()\n",
    "    return w/s if s>0 else w0\n",
    "\n",
    "def min_var_given_target(mu, cov, target, ub=1.0):\n",
    "    n = len(mu); w0 = np.ones(n)/n\n",
    "    cons = (\n",
    "        {\"type\":\"eq\",\"fun\": lambda w: np.sum(w) - 1.0},\n",
    "        {\"type\":\"eq\",\"fun\": lambda w: float(mu @ w) - target}\n",
    "    )\n",
    "    bnds = tuple((0.0, float(ub)) for _ in range(n))\n",
    "    obj = lambda w: float(w @ cov @ w)\n",
    "    res = minimize(obj, w0, method=\"SLSQP\", bounds=bnds, constraints=cons, options={\"maxiter\":1000})\n",
    "    if res.success and np.all(np.isfinite(res.x)):\n",
    "        w = np.maximum(res.x, 0); s = w.sum()\n",
    "        if s>0: return w/s\n",
    "    return None\n",
    "\n",
    "def tangency_weights(mu_d, cov_d, rf_d, ub=1.0):\n",
    "    n = len(mu_d); w0 = np.ones(n)/n\n",
    "    def neg_sharpe(w):\n",
    "        mu_p = float(w @ mu_d)\n",
    "        vol_p = np.sqrt(max(1e-12, w @ cov_d @ w))\n",
    "        return - (mu_p - rf_d) / (vol_p + 1e-12)\n",
    "    cons = ({\"type\":\"eq\",\"fun\": lambda w: np.sum(w) - 1.0},)\n",
    "    bnds = tuple((0.0, float(ub)) for _ in range(n))\n",
    "    res = minimize(neg_sharpe, w0, method=\"SLSQP\", bounds=bnds, constraints=cons, options={\"maxiter\":1000})\n",
    "    if res.success and np.all(np.isfinite(res.x)):\n",
    "        w = np.maximum(res.x, 0); s = w.sum()\n",
    "        return w/s if s>0 else np.ones(n)/n\n",
    "    return np.ones(n)/n\n",
    "\n",
    "def reseleccionar():\n",
    "    out_coef.clear_output(); out_select.clear_output()\n",
    "    START = start_sel.value.strip()\n",
    "    END   = end_sel.value.strip()\n",
    "    RF_A  = float(rf_sel.value)\n",
    "    MIN_ADV = float(min_adv_sel.value)\n",
    "    MAX_N = int(max_n_sel.value)\n",
    "    MIN_N = int(min_n_sel.value)\n",
    "    N_CL  = int(k_sel.value)\n",
    "    CAPC  = int(cap_sel.value)\n",
    "\n",
    "    px, vol = download_panel(UNIVERSE, START, END)\n",
    "    px = px.dropna(axis=1, how=\"any\")\n",
    "    vol = vol[px.columns]\n",
    "\n",
    "    adv_usd = (px * vol).rolling(60).median().iloc[-1].replace([np.inf,-np.inf], np.nan).dropna()\n",
    "    liq_keep = adv_usd[adv_usd >= MIN_ADV].index.tolist()\n",
    "    px = px[liq_keep]; vol = vol[liq_keep]\n",
    "    ret = np.log(px/px.shift(1)).dropna()\n",
    "    tickers_ok = list(px.columns)\n",
    "    if len(tickers_ok) < MIN_N:\n",
    "        out_select.append_stdout(\"Muy pocos activos tras filtro de liquidez/datos.\\n\")\n",
    "        return []\n",
    "\n",
    "    r60  = ret.tail(60).sum()\n",
    "    r126 = ret.tail(126).sum()\n",
    "    r252 = ret.tail(252).sum() if len(ret) >= 252 else ret.sum()\n",
    "    vol126 = ret.tail(126).std()\n",
    "    vol252 = ret.std()\n",
    "    neg = ret.copy(); neg[neg>0]=0\n",
    "    downvol = neg.std()\n",
    "\n",
    "    spy = \"SPY\" if \"SPY\" in ret.columns else tickers_ok[0]\n",
    "    Xbeta = np.vstack([ret[spy].values, np.ones(len(ret))]).T\n",
    "    betas, cors = {}, {}\n",
    "    for t in tickers_ok:\n",
    "        y = ret[t].values\n",
    "        b = np.linalg.lstsq(Xbeta, y, rcond=None)[0][0]\n",
    "        betas[t] = float(b)\n",
    "        cors[t] = float(np.corrcoef(ret[spy], ret[t])[0,1])\n",
    "\n",
    "    mdd = {}\n",
    "    w = min(len(ret), 252)\n",
    "    for t in tickers_ok:\n",
    "        mdd[t] = max_drawdown_from_returns(ret[t].tail(w))\n",
    "\n",
    "    liq = adv_usd[tickers_ok]\n",
    "    feats = pd.DataFrame({\n",
    "        \"momentum_60\":  r60,\n",
    "        \"momentum_126\": r126,\n",
    "        \"momentum_252\": r252,\n",
    "        \"vol_126\":      vol126,\n",
    "        \"vol_252\":      vol252,\n",
    "        \"down_vol\":     downvol,\n",
    "        \"beta_SPY\":     pd.Series(betas),\n",
    "        \"corr_SPY\":     pd.Series(cors),\n",
    "        \"mdd\":          pd.Series(mdd),\n",
    "        \"ADV_usd\":      liq\n",
    "    }).dropna()\n",
    "\n",
    "    for c in feats.columns:\n",
    "        feats[c] = winsorize(feats[c])\n",
    "\n",
    "    mu_a = ret[feats.index].mean()*252\n",
    "    vol_a = ret[feats.index].std()*np.sqrt(252)\n",
    "    sharpe = (mu_a - RF_A) / (vol_a.replace(0, np.nan))\n",
    "\n",
    "    X = StandardScaler().fit_transform(feats.fillna(feats.mean()))\n",
    "    y = sharpe.loc[feats.index].fillna(sharpe.median()).values\n",
    "    enet = ElasticNetCV(l1_ratio=[.2,.5,.8], cv=5, random_state=RANDOM_STATE).fit(X, y)\n",
    "    coef = pd.Series(enet.coef_, index=feats.columns).sort_values(ascending=False)\n",
    "\n",
    "    with out_coef:\n",
    "        print(\"Importancias (ElasticNet, Sharpe como target):\")\n",
    "        display(coef.to_frame(\"coef\").T)\n",
    "\n",
    "    coef_nz = coef[coef.abs()>0]\n",
    "    if coef_nz.empty:\n",
    "        score = ( +0.5*feats[\"momentum_126\"].rank(pct=True)\n",
    "                  +0.3*feats[\"momentum_252\"].rank(pct=True)\n",
    "                  -0.3*feats[\"vol_126\"].rank(pct=True)\n",
    "                  -0.2*feats[\"mdd\"].rank(pct=True)\n",
    "                  -0.2*feats[\"corr_SPY\"].rank(pct=True)\n",
    "                  +0.2*feats[\"ADV_usd\"].rank(pct=True) )\n",
    "    else:\n",
    "        Z = feats.apply(lambda s: (s - s.mean())/s.std(ddof=0))\n",
    "        score = Z[coef_nz.index].dot(coef_nz)\n",
    "\n",
    "    score = score.sort_values(ascending=False)\n",
    "\n",
    "    C = ret[score.index].corr().fillna(0).values\n",
    "    U, svals, Vt = np.linalg.svd(C - C.mean())\n",
    "    X2 = U[:, :min(5, U.shape[1])] * svals[:min(5, U.shape[1])]\n",
    "    km = KMeans(n_clusters=N_CL, n_init=20, random_state=RANDOM_STATE)\n",
    "    labels = km.fit_predict(X2)\n",
    "    lab_ser = pd.Series(labels, index=score.index, name=\"cluster\")\n",
    "\n",
    "    selected = []\n",
    "    for t in score.index:\n",
    "        c = int(lab_ser[t])\n",
    "        cnt_c = sum(1 for tt in selected if lab_ser[tt]==c)\n",
    "        if cnt_c < CAPC:\n",
    "            selected.append(t)\n",
    "        if len(selected) >= MAX_N:\n",
    "            break\n",
    "    if len(selected) < MIN_N:\n",
    "        selected = list(score.index[:MIN_N])\n",
    "\n",
    "    with out_select:\n",
    "        out_select.clear_output()\n",
    "        print(\"Seleccionados:\", \", \".join(selected))\n",
    "\n",
    "    out_head.value = f\"<b>Seleccionados:</b> {', '.join(selected)}\"\n",
    "    tickers_txt.value = \",\".join(selected)\n",
    "    start_mkv.value = START\n",
    "    end_mkv.value   = END\n",
    "    rf_mkv.value    = RF_A\n",
    "    if auto_compute.value:\n",
    "        compute_frontier(None)\n",
    "    return selected\n",
    "\n",
    "_frontier = []; _curr_tickers = []\n",
    "\n",
    "def compute_frontier(_):\n",
    "    out_plot.clear_output(); out_weights.clear_output(); out_info.clear_output()\n",
    "    global _frontier, _curr_tickers\n",
    "    _frontier = []; _curr_tickers = []\n",
    "\n",
    "    tickers = [t.strip().upper() for t in tickers_txt.value.split(\",\") if t.strip()]\n",
    "    tickers = list(dict.fromkeys(tickers))\n",
    "    if len(tickers)<2:\n",
    "        with out_info: print(\"Elige al menos 2 tickers.\"); return\n",
    "\n",
    "    START = start_mkv.value.strip()\n",
    "    END   = end_mkv.value.strip()\n",
    "    RF_A  = float(rf_mkv.value); rf_d = ann_to_daily(RF_A)\n",
    "    UB    = float(ubound.value)\n",
    "\n",
    "    try:\n",
    "        px = (yf.download(tickers, start=START, end=END, auto_adjust=True, progress=False)[\"Close\"]\n",
    "                .dropna(axis=1, how=\"any\"))\n",
    "    except Exception as e:\n",
    "        with out_info: print(\"Error descargando datos:\", e); return\n",
    "\n",
    "    if px.shape[1]<2:\n",
    "        with out_info: print(\"Muy pocos activos con datos completos.\"); return\n",
    "\n",
    "    ret = np.log(px/px.shift(1)).dropna()\n",
    "    mu_d = ret.mean().values\n",
    "    lw = LedoitWolf().fit(ret.values)\n",
    "    cov_d = lw.covariance_\n",
    "    _curr_tickers = list(px.columns)\n",
    "\n",
    "    pts = []\n",
    "    if obj_dd.value == \"Frontera (grid)\":\n",
    "        mu_min, mu_max = float(np.min(mu_d)), float(np.max(mu_d))\n",
    "        targets = np.linspace(mu_min+1e-6, mu_max-1e-6, int(grid_slider.value))\n",
    "        for tau in targets:\n",
    "            w = min_var_given_target(mu_d, cov_d, tau, ub=UB)\n",
    "            if w is None: \n",
    "                continue\n",
    "            mu_ann = float((mu_d @ w) * 252)\n",
    "            vol_ann = float(np.sqrt(w @ cov_d @ w) * np.sqrt(252))\n",
    "            pts.append({\"ret_ann\": mu_ann, \"vol_ann\": vol_ann, \"w\": w})\n",
    "        w_mv = min_variance_weights(cov_d, ub=UB)\n",
    "        pts.append({\"ret_ann\": float((mu_d @ w_mv)*252),\n",
    "                    \"vol_ann\": float(np.sqrt(w_mv @ cov_d @ w_mv)*np.sqrt(252)),\n",
    "                    \"w\": w_mv, \"tag\":\"MinVar\"})\n",
    "        w_tg = tangency_weights(mu_d, cov_d, rf_d, ub=UB)\n",
    "        pts.append({\"ret_ann\": float((mu_d @ w_tg)*252),\n",
    "                    \"vol_ann\": float(np.sqrt(w_tg @ cov_d @ w_tg)*np.sqrt(252)),\n",
    "                    \"w\": w_tg, \"tag\":\"Tangency\"})\n",
    "    elif obj_dd.value == \"Mín-Var\":\n",
    "        w_mv = min_variance_weights(cov_d, ub=UB)\n",
    "        pts = [{\"ret_ann\": float((mu_d @ w_mv)*252),\n",
    "                \"vol_ann\": float(np.sqrt(w_mv @ cov_d @ w_mv)*np.sqrt(252)),\n",
    "                \"w\": w_mv, \"tag\":\"MinVar\"}]\n",
    "    else:  \n",
    "        w_tg = tangency_weights(mu_d, cov_d, rf_d, ub=UB)\n",
    "        pts = [{\"ret_ann\": float((mu_d @ w_tg)*252),\n",
    "                \"vol_ann\": float(np.sqrt(w_tg @ cov_d @ w_tg)*np.sqrt(252)),\n",
    "                \"w\": w_tg, \"tag\":\"Tangency\"}]\n",
    "\n",
    "    if len(pts)==0:\n",
    "        with out_info: print(\"No se pudo construir la frontera.\"); return\n",
    "\n",
    "    _frontier = sorted(pts, key=lambda d: d[\"vol_ann\"])\n",
    "    sel_idx_slider.max = max(0, len(_frontier)-1)\n",
    "    sel_idx_slider.value = np.argmin([p[\"vol_ann\"] for p in _frontier])\n",
    "\n",
    "    with out_plot:\n",
    "        fig, ax = plt.subplots(figsize=(7,5))\n",
    "        xs = [p[\"vol_ann\"] for p in _frontier]\n",
    "        ys = [p[\"ret_ann\"] for p in _frontier]\n",
    "        ax.plot(xs, ys, marker='o', linestyle='-')\n",
    "        try:\n",
    "            i_mv = [i for i,p in enumerate(_frontier) if p.get(\"tag\")==\"MinVar\"][0]\n",
    "            ax.scatter([_frontier[i_mv][\"vol_ann\"]], [_frontier[i_mv][\"ret_ann\"]], s=80)\n",
    "            ax.text(_frontier[i_mv][\"vol_ann\"], _frontier[i_mv][\"ret_ann\"], \"  MinVar\", va='bottom')\n",
    "        except: pass\n",
    "        try:\n",
    "            i_tg = [i for i,p in enumerate(_frontier) if p.get(\"tag\")==\"Tangency\"][0]\n",
    "            ax.scatter([_frontier[i_tg][\"vol_ann\"]], [_frontier[i_tg][\"ret_ann\"]], s=80)\n",
    "            ax.text(_frontier[i_tg][\"vol_ann\"], _frontier[i_tg][\"ret_ann\"], \"  Tangency\", va='bottom')\n",
    "        except: pass\n",
    "        ax.set_xlabel(\"Volatilidad anual\"); ax.set_ylabel(\"Retorno anual\")\n",
    "        ax.set_title(\"Frontera eficiente (long-only)\")\n",
    "        plt.show()\n",
    "\n",
    "    update_selection(None)\n",
    "\n",
    "def update_selection(change):\n",
    "    out_weights.clear_output(); out_info.clear_output()\n",
    "    if not _frontier: return\n",
    "    i = int(sel_idx_slider.value)\n",
    "    i = max(0, min(i, len(_frontier)-1))\n",
    "    w = _frontier[i][\"w\"]; vol = _frontier[i][\"vol_ann\"]; ret_ = _frontier[i][\"ret_ann\"]\n",
    "    with out_weights:\n",
    "        dfw = pd.DataFrame({\"Ticker\": _curr_tickers, \"Weight\": np.round(w, 4)})\n",
    "        display(dfw)\n",
    "        fig, ax = plt.subplots(figsize=(7,3))\n",
    "        ax.bar(np.arange(len(w)), w)\n",
    "        ax.set_xticks(np.arange(len(w))); ax.set_xticklabels(_curr_tickers, rotation=45, ha='right')\n",
    "        ax.set_ylabel(\"Weight\"); ax.set_title(\"Pesos del punto seleccionado\")\n",
    "        plt.tight_layout(); plt.show()\n",
    "    with out_info:\n",
    "        sharpe = ret_/max(vol, 1e-12)\n",
    "        print(f\"Índice: {i} | Ret anual: {ret_:.4f} | Vol anual: {vol:.4f} | Sharpe≈ {sharpe:.4f}\")\n",
    "\n",
    "reselect_btn.on_click(lambda _: reseleccionar())\n",
    "compute_btn.on_click(compute_frontier)\n",
    "sel_idx_slider.observe(update_selection, names=\"value\")\n",
    "\n",
    "ui_select = VBox([\n",
    "    HTML(\"<h3>Selección (Sharpe→ElasticNet + Diversificación por clúster)</h3>\"),\n",
    "    HBox([start_sel, end_sel, rf_sel, min_adv_sel]),\n",
    "    HBox([max_n_sel, min_n_sel, k_sel, cap_sel]),\n",
    "    HBox([reselect_btn, auto_compute]),\n",
    "    out_head,\n",
    "    out_coef,\n",
    "    out_select\n",
    "])\n",
    "\n",
    "ui_markowitz = VBox([\n",
    "    HTML(\"<h3>Asignación (Markowitz, Ledoit–Wolf, Long-Only)</h3>\"),\n",
    "    HBox([tickers_txt]),\n",
    "    HBox([start_mkv, end_mkv, rf_mkv, grid_slider]),\n",
    "    HBox([obj_dd, ubound, compute_btn, sel_idx_slider]),\n",
    "    out_plot,\n",
    "    out_weights,\n",
    "    out_info\n",
    "])\n",
    "\n",
    "display(VBox([ui_select, ui_markowitz]))\n",
    "\n",
    "_ = reseleccionar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf20268-155c-41db-b9cf-fd1bd8bee429",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
